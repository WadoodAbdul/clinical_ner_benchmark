{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch --index-url https://download.pytorch.org/whl/cu118\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Result of Single Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Running the code below will save the outputs in the ../data/outputs/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/ncbi_disease contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/ncbi_disease\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/chia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/chia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/biored contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/biored\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/bc5cdr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/bc5cdr\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from clinical_ner.leaderboard import get_leaderboard_models, reproduce_leaderboard_results, load_leaderboard_model_and_config\n",
    "from clinical_ner.models import SpanExtractor\n",
    "from clinical_ner.evaluation import Evaluator\n",
    "from clinical_ner.benchmarks import NCER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NCBI', 'CHIA', 'BIORED', 'BC5CDR']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = NCER\n",
    "benchmark.tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the model_name has to be one already on the leaderboard\n",
    "# model_name = \"alvaroalon2/biobert_diseases_ner\"\n",
    "# model_name = \"bioformers/bioformer-8L-ncbi-disease\"\n",
    "# model_name = \"Universal-NER/UniNER-7B-type\"\n",
    "# model_name = \"urchade/gliner_large_bio-v0.1\"\n",
    "# model_name = 'knowledgator/gliner-multitask-large-v0.5'\n",
    "model_name = 'gliner-community/gliner_large-v2.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 33.29it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GLiNER model gliner-community/gliner_large-v2.5\n"
     ]
    }
   ],
   "source": [
    "model, dataset_wise_config = load_leaderboard_model_and_config(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NCBI': {'label_normalization_map': {'disease': 'condition',\n",
       "   'medical condition': 'condition'}},\n",
       " 'CHIA': {'label_normalization_map': {'drug': 'drug',\n",
       "   'chemical': 'drug',\n",
       "   'medical condition': 'condition',\n",
       "   'disease': 'condition',\n",
       "   'procedure': 'procedure',\n",
       "   'measurement': 'measurement'}},\n",
       " 'BIORED': {'label_normalization_map': {'drug': 'drug',\n",
       "   'chemical': 'drug',\n",
       "   'medical condition': 'condition',\n",
       "   'disease': 'condition',\n",
       "   'gene': 'gene',\n",
       "   'gene variant': 'gene variant'}},\n",
       " 'BC5CDR': {'label_normalization_map': {'drug': 'drug',\n",
       "   'chemical': 'drug',\n",
       "   'medical condition': 'condition',\n",
       "   'disease': 'condition'}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_wise_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/ncbi_disease contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/ncbi_disease\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [00:39<00:00,  2.52it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 1710.14 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 810, 'incorrect': 0, 'partial': 0, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.6858594411515665, 'recall': 0.84375, 'f1': 0.7566557683325548}, 'partial': {'correct': 686, 'incorrect': 0, 'partial': 124, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.6333615580016935, 'recall': 0.7791666666666667, 'f1': 0.6987389070527791}, 'strict': {'correct': 686, 'incorrect': 124, 'partial': 0, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.5808636748518204, 'recall': 0.7145833333333333, 'f1': 0.6408220457730033}, 'exact': {'correct': 686, 'incorrect': 124, 'partial': 0, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.5808636748518204, 'recall': 0.7145833333333333, 'f1': 0.6408220457730033}}\n",
      "{'condition': {'ent_type': {'correct': 810, 'incorrect': 0, 'partial': 0, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.6858594411515665, 'recall': 0.84375, 'f1': 0.7566557683325548}, 'partial': {'correct': 686, 'incorrect': 0, 'partial': 124, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.6333615580016935, 'recall': 0.7791666666666667, 'f1': 0.6987389070527791}, 'strict': {'correct': 686, 'incorrect': 124, 'partial': 0, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.5808636748518204, 'recall': 0.7145833333333333, 'f1': 0.6408220457730033}, 'exact': {'correct': 686, 'incorrect': 124, 'partial': 0, 'missed': 150, 'spurious': 371, 'possible': 960, 'actual': 1181, 'precision': 0.5808636748518204, 'recall': 0.7145833333333333, 'f1': 0.6408220457730033}}}\n",
      "f1-score: 0.7566557683325548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/chia contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/chia\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 191/191 [00:46<00:00,  4.12it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 191/191 [00:00<00:00, 2541.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 1514, 'incorrect': 178, 'partial': 0, 'missed': 264, 'spurious': 830, 'possible': 1956, 'actual': 2522, 'precision': 0.6003172085646312, 'recall': 0.7740286298568507, 'f1': 0.6761947297900849}, 'partial': {'correct': 1382, 'incorrect': 0, 'partial': 310, 'missed': 264, 'spurious': 830, 'possible': 1956, 'actual': 2522, 'precision': 0.6094369547977796, 'recall': 0.7857873210633947, 'f1': 0.6864671728450202}, 'strict': {'correct': 1276, 'incorrect': 416, 'partial': 0, 'missed': 264, 'spurious': 830, 'possible': 1956, 'actual': 2522, 'precision': 0.5059476605868358, 'recall': 0.6523517382413088, 'f1': 0.5698972755694506}, 'exact': {'correct': 1382, 'incorrect': 310, 'partial': 0, 'missed': 264, 'spurious': 830, 'possible': 1956, 'actual': 2522, 'precision': 0.5479777954004759, 'recall': 0.7065439672801636, 'f1': 0.6172398392139348}}\n",
      "{'procedure': {'ent_type': {'correct': 187, 'incorrect': 55, 'partial': 0, 'missed': 58, 'spurious': 280, 'possible': 300, 'actual': 522, 'precision': 0.35823754789272033, 'recall': 0.6233333333333333, 'f1': 0.45498783454987834}, 'partial': {'correct': 184, 'incorrect': 0, 'partial': 58, 'missed': 58, 'spurious': 280, 'possible': 300, 'actual': 522, 'precision': 0.40804597701149425, 'recall': 0.71, 'f1': 0.5182481751824817}, 'strict': {'correct': 149, 'incorrect': 93, 'partial': 0, 'missed': 58, 'spurious': 280, 'possible': 300, 'actual': 522, 'precision': 0.28544061302681994, 'recall': 0.49666666666666665, 'f1': 0.36253041362530414}, 'exact': {'correct': 184, 'incorrect': 58, 'partial': 0, 'missed': 58, 'spurious': 280, 'possible': 300, 'actual': 522, 'precision': 0.3524904214559387, 'recall': 0.6133333333333333, 'f1': 0.4476885644768856}}, 'measurement': {'ent_type': {'correct': 134, 'incorrect': 85, 'partial': 0, 'missed': 39, 'spurious': 127, 'possible': 258, 'actual': 346, 'precision': 0.3872832369942196, 'recall': 0.5193798449612403, 'f1': 0.44370860927152317}, 'partial': {'correct': 162, 'incorrect': 0, 'partial': 57, 'missed': 39, 'spurious': 127, 'possible': 258, 'actual': 346, 'precision': 0.5505780346820809, 'recall': 0.7383720930232558, 'f1': 0.6307947019867549}, 'strict': {'correct': 111, 'incorrect': 108, 'partial': 0, 'missed': 39, 'spurious': 127, 'possible': 258, 'actual': 346, 'precision': 0.3208092485549133, 'recall': 0.43023255813953487, 'f1': 0.3675496688741721}, 'exact': {'correct': 162, 'incorrect': 57, 'partial': 0, 'missed': 39, 'spurious': 127, 'possible': 258, 'actual': 346, 'precision': 0.4682080924855491, 'recall': 0.627906976744186, 'f1': 0.5364238410596026}}, 'drug': {'ent_type': {'correct': 265, 'incorrect': 9, 'partial': 0, 'missed': 21, 'spurious': 163, 'possible': 295, 'actual': 437, 'precision': 0.6064073226544623, 'recall': 0.8983050847457628, 'f1': 0.7240437158469945}, 'partial': {'correct': 249, 'incorrect': 0, 'partial': 25, 'missed': 21, 'spurious': 163, 'possible': 295, 'actual': 437, 'precision': 0.5983981693363845, 'recall': 0.8864406779661017, 'f1': 0.7144808743169399}, 'strict': {'correct': 241, 'incorrect': 33, 'partial': 0, 'missed': 21, 'spurious': 163, 'possible': 295, 'actual': 437, 'precision': 0.551487414187643, 'recall': 0.8169491525423729, 'f1': 0.6584699453551913}, 'exact': {'correct': 249, 'incorrect': 25, 'partial': 0, 'missed': 21, 'spurious': 163, 'possible': 295, 'actual': 437, 'precision': 0.5697940503432495, 'recall': 0.8440677966101695, 'f1': 0.6803278688524591}}, 'condition': {'ent_type': {'correct': 928, 'incorrect': 29, 'partial': 0, 'missed': 146, 'spurious': 260, 'possible': 1103, 'actual': 1217, 'precision': 0.76253081347576, 'recall': 0.8413417951042611, 'f1': 0.8}, 'partial': {'correct': 787, 'incorrect': 0, 'partial': 170, 'missed': 146, 'spurious': 260, 'possible': 1103, 'actual': 1217, 'precision': 0.7165160230073953, 'recall': 0.7905711695376246, 'f1': 0.7517241379310345}, 'strict': {'correct': 775, 'incorrect': 182, 'partial': 0, 'missed': 146, 'spurious': 260, 'possible': 1103, 'actual': 1217, 'precision': 0.6368118323746919, 'recall': 0.7026291931097008, 'f1': 0.6681034482758621}, 'exact': {'correct': 787, 'incorrect': 170, 'partial': 0, 'missed': 146, 'spurious': 260, 'possible': 1103, 'actual': 1217, 'precision': 0.6466721446179129, 'recall': 0.71350861287398, 'f1': 0.678448275862069}}}\n",
      "f1-score: 0.6761947297900849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/biored contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/biored\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 100/100 [00:47<00:00,  2.11it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 2054.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 2174, 'incorrect': 281, 'partial': 0, 'missed': 637, 'spurious': 556, 'possible': 3092, 'actual': 3011, 'precision': 0.7220192627034208, 'recall': 0.703104786545925, 'f1': 0.7124365066360806}, 'partial': {'correct': 1906, 'incorrect': 0, 'partial': 549, 'missed': 637, 'spurious': 556, 'possible': 3092, 'actual': 3011, 'precision': 0.7241780139488542, 'recall': 0.7052069857697283, 'f1': 0.7145666065869245}, 'strict': {'correct': 1810, 'incorrect': 645, 'partial': 0, 'missed': 637, 'spurious': 556, 'possible': 3092, 'actual': 3011, 'precision': 0.6011291929591498, 'recall': 0.5853816300129366, 'f1': 0.5931509093888252}, 'exact': {'correct': 1906, 'incorrect': 549, 'partial': 0, 'missed': 637, 'spurious': 556, 'possible': 3092, 'actual': 3011, 'precision': 0.6330122882763202, 'recall': 0.6164294954721863, 'f1': 0.624610847124365}}\n",
      "{'gene': {'ent_type': {'correct': 761, 'incorrect': 210, 'partial': 0, 'missed': 209, 'spurious': 103, 'possible': 1180, 'actual': 1074, 'precision': 0.7085661080074488, 'recall': 0.6449152542372881, 'f1': 0.6752440106477374}, 'partial': {'correct': 695, 'incorrect': 0, 'partial': 276, 'missed': 209, 'spurious': 103, 'possible': 1180, 'actual': 1074, 'precision': 0.7756052141527002, 'recall': 0.7059322033898305, 'f1': 0.7391304347826088}, 'strict': {'correct': 608, 'incorrect': 363, 'partial': 0, 'missed': 209, 'spurious': 103, 'possible': 1180, 'actual': 1074, 'precision': 0.5661080074487895, 'recall': 0.5152542372881356, 'f1': 0.5394853593611357}, 'exact': {'correct': 695, 'incorrect': 276, 'partial': 0, 'missed': 209, 'spurious': 103, 'possible': 1180, 'actual': 1074, 'precision': 0.6471135940409684, 'recall': 0.5889830508474576, 'f1': 0.6166814551907719}}, 'drug': {'ent_type': {'correct': 516, 'incorrect': 51, 'partial': 0, 'missed': 187, 'spurious': 72, 'possible': 754, 'actual': 639, 'precision': 0.8075117370892019, 'recall': 0.6843501326259946, 'f1': 0.7408470926058865}, 'partial': {'correct': 473, 'incorrect': 0, 'partial': 94, 'missed': 187, 'spurious': 72, 'possible': 754, 'actual': 639, 'precision': 0.8137715179968701, 'recall': 0.6896551724137931, 'f1': 0.7465900933237617}, 'strict': {'correct': 467, 'incorrect': 100, 'partial': 0, 'missed': 187, 'spurious': 72, 'possible': 754, 'actual': 639, 'precision': 0.730829420970266, 'recall': 0.6193633952254642, 'f1': 0.6704953338119167}, 'exact': {'correct': 473, 'incorrect': 94, 'partial': 0, 'missed': 187, 'spurious': 72, 'possible': 754, 'actual': 639, 'precision': 0.7402190923317684, 'recall': 0.6273209549071618, 'f1': 0.6791098348887294}}, 'condition': {'ent_type': {'correct': 755, 'incorrect': 4, 'partial': 0, 'missed': 158, 'spurious': 213, 'possible': 917, 'actual': 972, 'precision': 0.7767489711934157, 'recall': 0.8233369683751364, 'f1': 0.7993647432503971}, 'partial': {'correct': 645, 'incorrect': 0, 'partial': 114, 'missed': 158, 'spurious': 213, 'possible': 917, 'actual': 972, 'precision': 0.7222222222222222, 'recall': 0.7655398037077427, 'f1': 0.7432503970354685}, 'strict': {'correct': 644, 'incorrect': 115, 'partial': 0, 'missed': 158, 'spurious': 213, 'possible': 917, 'actual': 972, 'precision': 0.6625514403292181, 'recall': 0.7022900763358778, 'f1': 0.6818422445738486}, 'exact': {'correct': 645, 'incorrect': 114, 'partial': 0, 'missed': 158, 'spurious': 213, 'possible': 917, 'actual': 972, 'precision': 0.6635802469135802, 'recall': 0.7033805888767721, 'f1': 0.6829010058231869}}, 'gene variant': {'ent_type': {'correct': 142, 'incorrect': 16, 'partial': 0, 'missed': 83, 'spurious': 168, 'possible': 241, 'actual': 326, 'precision': 0.43558282208588955, 'recall': 0.5892116182572614, 'f1': 0.5008818342151675}, 'partial': {'correct': 93, 'incorrect': 0, 'partial': 65, 'missed': 83, 'spurious': 168, 'possible': 241, 'actual': 326, 'precision': 0.38496932515337423, 'recall': 0.520746887966805, 'f1': 0.4426807760141093}, 'strict': {'correct': 91, 'incorrect': 67, 'partial': 0, 'missed': 83, 'spurious': 168, 'possible': 241, 'actual': 326, 'precision': 0.2791411042944785, 'recall': 0.3775933609958506, 'f1': 0.3209876543209877}, 'exact': {'correct': 93, 'incorrect': 65, 'partial': 0, 'missed': 83, 'spurious': 168, 'possible': 241, 'actual': 326, 'precision': 0.2852760736196319, 'recall': 0.38589211618257263, 'f1': 0.328042328042328}}}\n",
      "f1-score: 0.7124365066360806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/hf_ner_leaderboard/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for bigbio/bc5cdr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/bigbio/bc5cdr\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 500/500 [03:17<00:00,  2.53it/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 500/500 [00:00<00:00, 8854.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 8723, 'incorrect': 239, 'partial': 0, 'missed': 962, 'spurious': 2860, 'possible': 9924, 'actual': 11822, 'precision': 0.7378616139401116, 'recall': 0.8789802498992342, 'f1': 0.8022624850547226}, 'partial': {'correct': 7364, 'incorrect': 0, 'partial': 1598, 'missed': 962, 'spurious': 2860, 'possible': 9924, 'actual': 11822, 'precision': 0.6904923024868889, 'recall': 0.8225513905683193, 'f1': 0.7507587602317668}, 'strict': {'correct': 7341, 'incorrect': 1621, 'partial': 0, 'missed': 962, 'spurious': 2860, 'possible': 9924, 'actual': 11822, 'precision': 0.6209609203180511, 'recall': 0.7397218863361548, 'f1': 0.6751586498666421}, 'exact': {'correct': 7364, 'incorrect': 1598, 'partial': 0, 'missed': 962, 'spurious': 2860, 'possible': 9924, 'actual': 11822, 'precision': 0.6229064456098798, 'recall': 0.7420395002015316, 'f1': 0.6772739814218707}}\n",
      "{'drug': {'ent_type': {'correct': 4682, 'incorrect': 210, 'partial': 0, 'missed': 502, 'spurious': 1063, 'possible': 5394, 'actual': 5955, 'precision': 0.7862300587741394, 'recall': 0.8680014831294031, 'f1': 0.8250947220019386}, 'partial': {'correct': 3946, 'incorrect': 0, 'partial': 946, 'missed': 502, 'spurious': 1063, 'possible': 5394, 'actual': 5955, 'precision': 0.7420654911838791, 'recall': 0.8192436040044494, 'f1': 0.7787470261697067}, 'strict': {'correct': 3928, 'incorrect': 964, 'partial': 0, 'missed': 502, 'spurious': 1063, 'possible': 5394, 'actual': 5955, 'precision': 0.6596137699412259, 'recall': 0.7282165368928439, 'f1': 0.692219578817517}, 'exact': {'correct': 3946, 'incorrect': 946, 'partial': 0, 'missed': 502, 'spurious': 1063, 'possible': 5394, 'actual': 5955, 'precision': 0.6626364399664147, 'recall': 0.7315535780496848, 'f1': 0.6953916644638294}}, 'condition': {'ent_type': {'correct': 4041, 'incorrect': 29, 'partial': 0, 'missed': 460, 'spurious': 1797, 'possible': 4530, 'actual': 5867, 'precision': 0.6887676836543378, 'recall': 0.8920529801324504, 'f1': 0.7773396171972684}, 'partial': {'correct': 3418, 'incorrect': 0, 'partial': 652, 'missed': 460, 'spurious': 1797, 'possible': 4530, 'actual': 5867, 'precision': 0.6381455599113687, 'recall': 0.8264900662251655, 'f1': 0.7202077522362219}, 'strict': {'correct': 3413, 'incorrect': 657, 'partial': 0, 'missed': 460, 'spurious': 1797, 'possible': 4530, 'actual': 5867, 'precision': 0.5817283108914266, 'recall': 0.7534216335540839, 'f1': 0.6565355390978166}, 'exact': {'correct': 3418, 'incorrect': 652, 'partial': 0, 'missed': 460, 'spurious': 1797, 'possible': 4530, 'actual': 5867, 'precision': 0.5825805351968638, 'recall': 0.7545253863134658, 'f1': 0.6574973550062517}}}\n",
      "f1-score: 0.8022624850547226\n",
      "CPU times: user 4h 21min 22s, sys: 3min 52s, total: 4h 25min 14s\n",
      "Wall time: 5min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NCBI': {'results': {'ent_type': {'correct': 810,\n",
       "    'incorrect': 0,\n",
       "    'partial': 0,\n",
       "    'missed': 150,\n",
       "    'spurious': 371,\n",
       "    'possible': 960,\n",
       "    'actual': 1181,\n",
       "    'precision': 0.6858594411515665,\n",
       "    'recall': 0.84375,\n",
       "    'f1': 0.7566557683325548},\n",
       "   'partial': {'correct': 686,\n",
       "    'incorrect': 0,\n",
       "    'partial': 124,\n",
       "    'missed': 150,\n",
       "    'spurious': 371,\n",
       "    'possible': 960,\n",
       "    'actual': 1181,\n",
       "    'precision': 0.6333615580016935,\n",
       "    'recall': 0.7791666666666667,\n",
       "    'f1': 0.6987389070527791},\n",
       "   'strict': {'correct': 686,\n",
       "    'incorrect': 124,\n",
       "    'partial': 0,\n",
       "    'missed': 150,\n",
       "    'spurious': 371,\n",
       "    'possible': 960,\n",
       "    'actual': 1181,\n",
       "    'precision': 0.5808636748518204,\n",
       "    'recall': 0.7145833333333333,\n",
       "    'f1': 0.6408220457730033},\n",
       "   'exact': {'correct': 686,\n",
       "    'incorrect': 124,\n",
       "    'partial': 0,\n",
       "    'missed': 150,\n",
       "    'spurious': 371,\n",
       "    'possible': 960,\n",
       "    'actual': 1181,\n",
       "    'precision': 0.5808636748518204,\n",
       "    'recall': 0.7145833333333333,\n",
       "    'f1': 0.6408220457730033}},\n",
       "  'results_per_tag': {'condition': {'ent_type': {'correct': 810,\n",
       "     'incorrect': 0,\n",
       "     'partial': 0,\n",
       "     'missed': 150,\n",
       "     'spurious': 371,\n",
       "     'possible': 960,\n",
       "     'actual': 1181,\n",
       "     'precision': 0.6858594411515665,\n",
       "     'recall': 0.84375,\n",
       "     'f1': 0.7566557683325548},\n",
       "    'partial': {'correct': 686,\n",
       "     'incorrect': 0,\n",
       "     'partial': 124,\n",
       "     'missed': 150,\n",
       "     'spurious': 371,\n",
       "     'possible': 960,\n",
       "     'actual': 1181,\n",
       "     'precision': 0.6333615580016935,\n",
       "     'recall': 0.7791666666666667,\n",
       "     'f1': 0.6987389070527791},\n",
       "    'strict': {'correct': 686,\n",
       "     'incorrect': 124,\n",
       "     'partial': 0,\n",
       "     'missed': 150,\n",
       "     'spurious': 371,\n",
       "     'possible': 960,\n",
       "     'actual': 1181,\n",
       "     'precision': 0.5808636748518204,\n",
       "     'recall': 0.7145833333333333,\n",
       "     'f1': 0.6408220457730033},\n",
       "    'exact': {'correct': 686,\n",
       "     'incorrect': 124,\n",
       "     'partial': 0,\n",
       "     'missed': 150,\n",
       "     'spurious': 371,\n",
       "     'possible': 960,\n",
       "     'actual': 1181,\n",
       "     'precision': 0.5808636748518204,\n",
       "     'recall': 0.7145833333333333,\n",
       "     'f1': 0.6408220457730033}}}},\n",
       " 'CHIA': {'results': {'ent_type': {'correct': 1514,\n",
       "    'incorrect': 178,\n",
       "    'partial': 0,\n",
       "    'missed': 264,\n",
       "    'spurious': 830,\n",
       "    'possible': 1956,\n",
       "    'actual': 2522,\n",
       "    'precision': 0.6003172085646312,\n",
       "    'recall': 0.7740286298568507,\n",
       "    'f1': 0.6761947297900849},\n",
       "   'partial': {'correct': 1382,\n",
       "    'incorrect': 0,\n",
       "    'partial': 310,\n",
       "    'missed': 264,\n",
       "    'spurious': 830,\n",
       "    'possible': 1956,\n",
       "    'actual': 2522,\n",
       "    'precision': 0.6094369547977796,\n",
       "    'recall': 0.7857873210633947,\n",
       "    'f1': 0.6864671728450202},\n",
       "   'strict': {'correct': 1276,\n",
       "    'incorrect': 416,\n",
       "    'partial': 0,\n",
       "    'missed': 264,\n",
       "    'spurious': 830,\n",
       "    'possible': 1956,\n",
       "    'actual': 2522,\n",
       "    'precision': 0.5059476605868358,\n",
       "    'recall': 0.6523517382413088,\n",
       "    'f1': 0.5698972755694506},\n",
       "   'exact': {'correct': 1382,\n",
       "    'incorrect': 310,\n",
       "    'partial': 0,\n",
       "    'missed': 264,\n",
       "    'spurious': 830,\n",
       "    'possible': 1956,\n",
       "    'actual': 2522,\n",
       "    'precision': 0.5479777954004759,\n",
       "    'recall': 0.7065439672801636,\n",
       "    'f1': 0.6172398392139348}},\n",
       "  'results_per_tag': {'procedure': {'ent_type': {'correct': 187,\n",
       "     'incorrect': 55,\n",
       "     'partial': 0,\n",
       "     'missed': 58,\n",
       "     'spurious': 280,\n",
       "     'possible': 300,\n",
       "     'actual': 522,\n",
       "     'precision': 0.35823754789272033,\n",
       "     'recall': 0.6233333333333333,\n",
       "     'f1': 0.45498783454987834},\n",
       "    'partial': {'correct': 184,\n",
       "     'incorrect': 0,\n",
       "     'partial': 58,\n",
       "     'missed': 58,\n",
       "     'spurious': 280,\n",
       "     'possible': 300,\n",
       "     'actual': 522,\n",
       "     'precision': 0.40804597701149425,\n",
       "     'recall': 0.71,\n",
       "     'f1': 0.5182481751824817},\n",
       "    'strict': {'correct': 149,\n",
       "     'incorrect': 93,\n",
       "     'partial': 0,\n",
       "     'missed': 58,\n",
       "     'spurious': 280,\n",
       "     'possible': 300,\n",
       "     'actual': 522,\n",
       "     'precision': 0.28544061302681994,\n",
       "     'recall': 0.49666666666666665,\n",
       "     'f1': 0.36253041362530414},\n",
       "    'exact': {'correct': 184,\n",
       "     'incorrect': 58,\n",
       "     'partial': 0,\n",
       "     'missed': 58,\n",
       "     'spurious': 280,\n",
       "     'possible': 300,\n",
       "     'actual': 522,\n",
       "     'precision': 0.3524904214559387,\n",
       "     'recall': 0.6133333333333333,\n",
       "     'f1': 0.4476885644768856}},\n",
       "   'measurement': {'ent_type': {'correct': 134,\n",
       "     'incorrect': 85,\n",
       "     'partial': 0,\n",
       "     'missed': 39,\n",
       "     'spurious': 127,\n",
       "     'possible': 258,\n",
       "     'actual': 346,\n",
       "     'precision': 0.3872832369942196,\n",
       "     'recall': 0.5193798449612403,\n",
       "     'f1': 0.44370860927152317},\n",
       "    'partial': {'correct': 162,\n",
       "     'incorrect': 0,\n",
       "     'partial': 57,\n",
       "     'missed': 39,\n",
       "     'spurious': 127,\n",
       "     'possible': 258,\n",
       "     'actual': 346,\n",
       "     'precision': 0.5505780346820809,\n",
       "     'recall': 0.7383720930232558,\n",
       "     'f1': 0.6307947019867549},\n",
       "    'strict': {'correct': 111,\n",
       "     'incorrect': 108,\n",
       "     'partial': 0,\n",
       "     'missed': 39,\n",
       "     'spurious': 127,\n",
       "     'possible': 258,\n",
       "     'actual': 346,\n",
       "     'precision': 0.3208092485549133,\n",
       "     'recall': 0.43023255813953487,\n",
       "     'f1': 0.3675496688741721},\n",
       "    'exact': {'correct': 162,\n",
       "     'incorrect': 57,\n",
       "     'partial': 0,\n",
       "     'missed': 39,\n",
       "     'spurious': 127,\n",
       "     'possible': 258,\n",
       "     'actual': 346,\n",
       "     'precision': 0.4682080924855491,\n",
       "     'recall': 0.627906976744186,\n",
       "     'f1': 0.5364238410596026}},\n",
       "   'drug': {'ent_type': {'correct': 265,\n",
       "     'incorrect': 9,\n",
       "     'partial': 0,\n",
       "     'missed': 21,\n",
       "     'spurious': 163,\n",
       "     'possible': 295,\n",
       "     'actual': 437,\n",
       "     'precision': 0.6064073226544623,\n",
       "     'recall': 0.8983050847457628,\n",
       "     'f1': 0.7240437158469945},\n",
       "    'partial': {'correct': 249,\n",
       "     'incorrect': 0,\n",
       "     'partial': 25,\n",
       "     'missed': 21,\n",
       "     'spurious': 163,\n",
       "     'possible': 295,\n",
       "     'actual': 437,\n",
       "     'precision': 0.5983981693363845,\n",
       "     'recall': 0.8864406779661017,\n",
       "     'f1': 0.7144808743169399},\n",
       "    'strict': {'correct': 241,\n",
       "     'incorrect': 33,\n",
       "     'partial': 0,\n",
       "     'missed': 21,\n",
       "     'spurious': 163,\n",
       "     'possible': 295,\n",
       "     'actual': 437,\n",
       "     'precision': 0.551487414187643,\n",
       "     'recall': 0.8169491525423729,\n",
       "     'f1': 0.6584699453551913},\n",
       "    'exact': {'correct': 249,\n",
       "     'incorrect': 25,\n",
       "     'partial': 0,\n",
       "     'missed': 21,\n",
       "     'spurious': 163,\n",
       "     'possible': 295,\n",
       "     'actual': 437,\n",
       "     'precision': 0.5697940503432495,\n",
       "     'recall': 0.8440677966101695,\n",
       "     'f1': 0.6803278688524591}},\n",
       "   'condition': {'ent_type': {'correct': 928,\n",
       "     'incorrect': 29,\n",
       "     'partial': 0,\n",
       "     'missed': 146,\n",
       "     'spurious': 260,\n",
       "     'possible': 1103,\n",
       "     'actual': 1217,\n",
       "     'precision': 0.76253081347576,\n",
       "     'recall': 0.8413417951042611,\n",
       "     'f1': 0.8},\n",
       "    'partial': {'correct': 787,\n",
       "     'incorrect': 0,\n",
       "     'partial': 170,\n",
       "     'missed': 146,\n",
       "     'spurious': 260,\n",
       "     'possible': 1103,\n",
       "     'actual': 1217,\n",
       "     'precision': 0.7165160230073953,\n",
       "     'recall': 0.7905711695376246,\n",
       "     'f1': 0.7517241379310345},\n",
       "    'strict': {'correct': 775,\n",
       "     'incorrect': 182,\n",
       "     'partial': 0,\n",
       "     'missed': 146,\n",
       "     'spurious': 260,\n",
       "     'possible': 1103,\n",
       "     'actual': 1217,\n",
       "     'precision': 0.6368118323746919,\n",
       "     'recall': 0.7026291931097008,\n",
       "     'f1': 0.6681034482758621},\n",
       "    'exact': {'correct': 787,\n",
       "     'incorrect': 170,\n",
       "     'partial': 0,\n",
       "     'missed': 146,\n",
       "     'spurious': 260,\n",
       "     'possible': 1103,\n",
       "     'actual': 1217,\n",
       "     'precision': 0.6466721446179129,\n",
       "     'recall': 0.71350861287398,\n",
       "     'f1': 0.678448275862069}}}},\n",
       " 'BIORED': {'results': {'ent_type': {'correct': 2174,\n",
       "    'incorrect': 281,\n",
       "    'partial': 0,\n",
       "    'missed': 637,\n",
       "    'spurious': 556,\n",
       "    'possible': 3092,\n",
       "    'actual': 3011,\n",
       "    'precision': 0.7220192627034208,\n",
       "    'recall': 0.703104786545925,\n",
       "    'f1': 0.7124365066360806},\n",
       "   'partial': {'correct': 1906,\n",
       "    'incorrect': 0,\n",
       "    'partial': 549,\n",
       "    'missed': 637,\n",
       "    'spurious': 556,\n",
       "    'possible': 3092,\n",
       "    'actual': 3011,\n",
       "    'precision': 0.7241780139488542,\n",
       "    'recall': 0.7052069857697283,\n",
       "    'f1': 0.7145666065869245},\n",
       "   'strict': {'correct': 1810,\n",
       "    'incorrect': 645,\n",
       "    'partial': 0,\n",
       "    'missed': 637,\n",
       "    'spurious': 556,\n",
       "    'possible': 3092,\n",
       "    'actual': 3011,\n",
       "    'precision': 0.6011291929591498,\n",
       "    'recall': 0.5853816300129366,\n",
       "    'f1': 0.5931509093888252},\n",
       "   'exact': {'correct': 1906,\n",
       "    'incorrect': 549,\n",
       "    'partial': 0,\n",
       "    'missed': 637,\n",
       "    'spurious': 556,\n",
       "    'possible': 3092,\n",
       "    'actual': 3011,\n",
       "    'precision': 0.6330122882763202,\n",
       "    'recall': 0.6164294954721863,\n",
       "    'f1': 0.624610847124365}},\n",
       "  'results_per_tag': {'gene': {'ent_type': {'correct': 761,\n",
       "     'incorrect': 210,\n",
       "     'partial': 0,\n",
       "     'missed': 209,\n",
       "     'spurious': 103,\n",
       "     'possible': 1180,\n",
       "     'actual': 1074,\n",
       "     'precision': 0.7085661080074488,\n",
       "     'recall': 0.6449152542372881,\n",
       "     'f1': 0.6752440106477374},\n",
       "    'partial': {'correct': 695,\n",
       "     'incorrect': 0,\n",
       "     'partial': 276,\n",
       "     'missed': 209,\n",
       "     'spurious': 103,\n",
       "     'possible': 1180,\n",
       "     'actual': 1074,\n",
       "     'precision': 0.7756052141527002,\n",
       "     'recall': 0.7059322033898305,\n",
       "     'f1': 0.7391304347826088},\n",
       "    'strict': {'correct': 608,\n",
       "     'incorrect': 363,\n",
       "     'partial': 0,\n",
       "     'missed': 209,\n",
       "     'spurious': 103,\n",
       "     'possible': 1180,\n",
       "     'actual': 1074,\n",
       "     'precision': 0.5661080074487895,\n",
       "     'recall': 0.5152542372881356,\n",
       "     'f1': 0.5394853593611357},\n",
       "    'exact': {'correct': 695,\n",
       "     'incorrect': 276,\n",
       "     'partial': 0,\n",
       "     'missed': 209,\n",
       "     'spurious': 103,\n",
       "     'possible': 1180,\n",
       "     'actual': 1074,\n",
       "     'precision': 0.6471135940409684,\n",
       "     'recall': 0.5889830508474576,\n",
       "     'f1': 0.6166814551907719}},\n",
       "   'drug': {'ent_type': {'correct': 516,\n",
       "     'incorrect': 51,\n",
       "     'partial': 0,\n",
       "     'missed': 187,\n",
       "     'spurious': 72,\n",
       "     'possible': 754,\n",
       "     'actual': 639,\n",
       "     'precision': 0.8075117370892019,\n",
       "     'recall': 0.6843501326259946,\n",
       "     'f1': 0.7408470926058865},\n",
       "    'partial': {'correct': 473,\n",
       "     'incorrect': 0,\n",
       "     'partial': 94,\n",
       "     'missed': 187,\n",
       "     'spurious': 72,\n",
       "     'possible': 754,\n",
       "     'actual': 639,\n",
       "     'precision': 0.8137715179968701,\n",
       "     'recall': 0.6896551724137931,\n",
       "     'f1': 0.7465900933237617},\n",
       "    'strict': {'correct': 467,\n",
       "     'incorrect': 100,\n",
       "     'partial': 0,\n",
       "     'missed': 187,\n",
       "     'spurious': 72,\n",
       "     'possible': 754,\n",
       "     'actual': 639,\n",
       "     'precision': 0.730829420970266,\n",
       "     'recall': 0.6193633952254642,\n",
       "     'f1': 0.6704953338119167},\n",
       "    'exact': {'correct': 473,\n",
       "     'incorrect': 94,\n",
       "     'partial': 0,\n",
       "     'missed': 187,\n",
       "     'spurious': 72,\n",
       "     'possible': 754,\n",
       "     'actual': 639,\n",
       "     'precision': 0.7402190923317684,\n",
       "     'recall': 0.6273209549071618,\n",
       "     'f1': 0.6791098348887294}},\n",
       "   'condition': {'ent_type': {'correct': 755,\n",
       "     'incorrect': 4,\n",
       "     'partial': 0,\n",
       "     'missed': 158,\n",
       "     'spurious': 213,\n",
       "     'possible': 917,\n",
       "     'actual': 972,\n",
       "     'precision': 0.7767489711934157,\n",
       "     'recall': 0.8233369683751364,\n",
       "     'f1': 0.7993647432503971},\n",
       "    'partial': {'correct': 645,\n",
       "     'incorrect': 0,\n",
       "     'partial': 114,\n",
       "     'missed': 158,\n",
       "     'spurious': 213,\n",
       "     'possible': 917,\n",
       "     'actual': 972,\n",
       "     'precision': 0.7222222222222222,\n",
       "     'recall': 0.7655398037077427,\n",
       "     'f1': 0.7432503970354685},\n",
       "    'strict': {'correct': 644,\n",
       "     'incorrect': 115,\n",
       "     'partial': 0,\n",
       "     'missed': 158,\n",
       "     'spurious': 213,\n",
       "     'possible': 917,\n",
       "     'actual': 972,\n",
       "     'precision': 0.6625514403292181,\n",
       "     'recall': 0.7022900763358778,\n",
       "     'f1': 0.6818422445738486},\n",
       "    'exact': {'correct': 645,\n",
       "     'incorrect': 114,\n",
       "     'partial': 0,\n",
       "     'missed': 158,\n",
       "     'spurious': 213,\n",
       "     'possible': 917,\n",
       "     'actual': 972,\n",
       "     'precision': 0.6635802469135802,\n",
       "     'recall': 0.7033805888767721,\n",
       "     'f1': 0.6829010058231869}},\n",
       "   'gene variant': {'ent_type': {'correct': 142,\n",
       "     'incorrect': 16,\n",
       "     'partial': 0,\n",
       "     'missed': 83,\n",
       "     'spurious': 168,\n",
       "     'possible': 241,\n",
       "     'actual': 326,\n",
       "     'precision': 0.43558282208588955,\n",
       "     'recall': 0.5892116182572614,\n",
       "     'f1': 0.5008818342151675},\n",
       "    'partial': {'correct': 93,\n",
       "     'incorrect': 0,\n",
       "     'partial': 65,\n",
       "     'missed': 83,\n",
       "     'spurious': 168,\n",
       "     'possible': 241,\n",
       "     'actual': 326,\n",
       "     'precision': 0.38496932515337423,\n",
       "     'recall': 0.520746887966805,\n",
       "     'f1': 0.4426807760141093},\n",
       "    'strict': {'correct': 91,\n",
       "     'incorrect': 67,\n",
       "     'partial': 0,\n",
       "     'missed': 83,\n",
       "     'spurious': 168,\n",
       "     'possible': 241,\n",
       "     'actual': 326,\n",
       "     'precision': 0.2791411042944785,\n",
       "     'recall': 0.3775933609958506,\n",
       "     'f1': 0.3209876543209877},\n",
       "    'exact': {'correct': 93,\n",
       "     'incorrect': 65,\n",
       "     'partial': 0,\n",
       "     'missed': 83,\n",
       "     'spurious': 168,\n",
       "     'possible': 241,\n",
       "     'actual': 326,\n",
       "     'precision': 0.2852760736196319,\n",
       "     'recall': 0.38589211618257263,\n",
       "     'f1': 0.328042328042328}}}},\n",
       " 'BC5CDR': {'results': {'ent_type': {'correct': 8723,\n",
       "    'incorrect': 239,\n",
       "    'partial': 0,\n",
       "    'missed': 962,\n",
       "    'spurious': 2860,\n",
       "    'possible': 9924,\n",
       "    'actual': 11822,\n",
       "    'precision': 0.7378616139401116,\n",
       "    'recall': 0.8789802498992342,\n",
       "    'f1': 0.8022624850547226},\n",
       "   'partial': {'correct': 7364,\n",
       "    'incorrect': 0,\n",
       "    'partial': 1598,\n",
       "    'missed': 962,\n",
       "    'spurious': 2860,\n",
       "    'possible': 9924,\n",
       "    'actual': 11822,\n",
       "    'precision': 0.6904923024868889,\n",
       "    'recall': 0.8225513905683193,\n",
       "    'f1': 0.7507587602317668},\n",
       "   'strict': {'correct': 7341,\n",
       "    'incorrect': 1621,\n",
       "    'partial': 0,\n",
       "    'missed': 962,\n",
       "    'spurious': 2860,\n",
       "    'possible': 9924,\n",
       "    'actual': 11822,\n",
       "    'precision': 0.6209609203180511,\n",
       "    'recall': 0.7397218863361548,\n",
       "    'f1': 0.6751586498666421},\n",
       "   'exact': {'correct': 7364,\n",
       "    'incorrect': 1598,\n",
       "    'partial': 0,\n",
       "    'missed': 962,\n",
       "    'spurious': 2860,\n",
       "    'possible': 9924,\n",
       "    'actual': 11822,\n",
       "    'precision': 0.6229064456098798,\n",
       "    'recall': 0.7420395002015316,\n",
       "    'f1': 0.6772739814218707}},\n",
       "  'results_per_tag': {'drug': {'ent_type': {'correct': 4682,\n",
       "     'incorrect': 210,\n",
       "     'partial': 0,\n",
       "     'missed': 502,\n",
       "     'spurious': 1063,\n",
       "     'possible': 5394,\n",
       "     'actual': 5955,\n",
       "     'precision': 0.7862300587741394,\n",
       "     'recall': 0.8680014831294031,\n",
       "     'f1': 0.8250947220019386},\n",
       "    'partial': {'correct': 3946,\n",
       "     'incorrect': 0,\n",
       "     'partial': 946,\n",
       "     'missed': 502,\n",
       "     'spurious': 1063,\n",
       "     'possible': 5394,\n",
       "     'actual': 5955,\n",
       "     'precision': 0.7420654911838791,\n",
       "     'recall': 0.8192436040044494,\n",
       "     'f1': 0.7787470261697067},\n",
       "    'strict': {'correct': 3928,\n",
       "     'incorrect': 964,\n",
       "     'partial': 0,\n",
       "     'missed': 502,\n",
       "     'spurious': 1063,\n",
       "     'possible': 5394,\n",
       "     'actual': 5955,\n",
       "     'precision': 0.6596137699412259,\n",
       "     'recall': 0.7282165368928439,\n",
       "     'f1': 0.692219578817517},\n",
       "    'exact': {'correct': 3946,\n",
       "     'incorrect': 946,\n",
       "     'partial': 0,\n",
       "     'missed': 502,\n",
       "     'spurious': 1063,\n",
       "     'possible': 5394,\n",
       "     'actual': 5955,\n",
       "     'precision': 0.6626364399664147,\n",
       "     'recall': 0.7315535780496848,\n",
       "     'f1': 0.6953916644638294}},\n",
       "   'condition': {'ent_type': {'correct': 4041,\n",
       "     'incorrect': 29,\n",
       "     'partial': 0,\n",
       "     'missed': 460,\n",
       "     'spurious': 1797,\n",
       "     'possible': 4530,\n",
       "     'actual': 5867,\n",
       "     'precision': 0.6887676836543378,\n",
       "     'recall': 0.8920529801324504,\n",
       "     'f1': 0.7773396171972684},\n",
       "    'partial': {'correct': 3418,\n",
       "     'incorrect': 0,\n",
       "     'partial': 652,\n",
       "     'missed': 460,\n",
       "     'spurious': 1797,\n",
       "     'possible': 4530,\n",
       "     'actual': 5867,\n",
       "     'precision': 0.6381455599113687,\n",
       "     'recall': 0.8264900662251655,\n",
       "     'f1': 0.7202077522362219},\n",
       "    'strict': {'correct': 3413,\n",
       "     'incorrect': 657,\n",
       "     'partial': 0,\n",
       "     'missed': 460,\n",
       "     'spurious': 1797,\n",
       "     'possible': 4530,\n",
       "     'actual': 5867,\n",
       "     'precision': 0.5817283108914266,\n",
       "     'recall': 0.7534216335540839,\n",
       "     'f1': 0.6565355390978166},\n",
       "    'exact': {'correct': 3418,\n",
       "     'incorrect': 652,\n",
       "     'partial': 0,\n",
       "     'missed': 460,\n",
       "     'spurious': 1797,\n",
       "     'possible': 4530,\n",
       "     'actual': 5867,\n",
       "     'precision': 0.5825805351968638,\n",
       "     'recall': 0.7545253863134658,\n",
       "     'f1': 0.6574973550062517}}}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = Evaluator(model, benchmark=benchmark, dataset_wise_config=dataset_wise_config)\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing complete Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinical_ner.leaderboard import get_leaderboard_models, reproduce_leaderboard_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the list of existing models on the leaderboard\n",
    "leaderboard_models = get_leaderboard_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs the same evaluation script used for the benchmark and stores the results\n",
    "reproduce_leaderboard_results(models=leaderboard_models,\n",
    "                                output_dir='./reproduced_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_ner_leaderboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
