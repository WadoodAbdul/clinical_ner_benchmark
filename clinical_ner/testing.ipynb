{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/medical_coder_ner/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from medics_ner.models import SpanExtractor\n",
    "from medics_ner.evaluation import Evaluator\n",
    "from medics_ner.benchmarks import MEDICS_NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "benchmark = MEDICS_NER # or use a specific benchmark\n",
    "# or \n",
    "# tasks = mteb.get_tasks(...) # get specific tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"alvaroalon2/biobert_diseases_ner\"\n",
    "\n",
    "# # this is model and dataset specific.\n",
    "# dataset_wise_config = {\n",
    "#         \"NCBI\": {\"label_normalization_map\": {\"DISEASE\": \"condition\"}}\n",
    "#     }\n",
    "# # load a predefined model (or for a custom implementation see https://github.com/WadoodAbdul/medics_ner/blob/main/docs/custom_model_implementation.md)\n",
    "# model = SpanExtractor.from_predefined(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/users/ext_mohammed.abdul.wadood/miniconda3/envs/medical_coder_ner/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.04it/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HF Decoder NER model identifier='Universal-NER/UniNER-7B-type' with model_kwargs={}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Universal-NER/UniNER-7B-type\"\n",
    "\n",
    "# this is model and dataset specific.\n",
    "dataset_wise_config = {\n",
    "        \"NCBI\": {\n",
    "            \"label_normalization_map\": {\"DISEASE\": \"condition\"},\n",
    "            \"prompt_file_path\" : \"../data/inputs/prompt_templates/universal_ner.jinja\"\n",
    "            }\n",
    "    }\n",
    "# load a predefined model (or for a custom implementation see https://github.com/WadoodAbdul/medics_ner/blob/main/docs/custom_model_implementation.md)\n",
    "model = SpanExtractor.from_predefined(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 10/200 [00:12<03:20,  1.05s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|██████████| 200/200 [05:06<00:00,  1.53s/it]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 200/200 [00:00<00:00, 3218.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.8203445447087777, 'recall': 0.5652911249293386, 'f1': 0.6693440428380188}, 'partial': {'correct': 776, 'incorrect': 0, 'partial': 224, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.7284659557013946, 'recall': 0.5019785189372526, 'f1': 0.5943775100401606}, 'strict': {'correct': 776, 'incorrect': 224, 'partial': 0, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.6365873666940115, 'recall': 0.43866591294516677, 'f1': 0.5194109772423026}, 'exact': {'correct': 776, 'incorrect': 224, 'partial': 0, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.6365873666940115, 'recall': 0.43866591294516677, 'f1': 0.5194109772423026}}\n",
      "{'condition': {'ent_type': {'correct': 1000, 'incorrect': 0, 'partial': 0, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.8203445447087777, 'recall': 0.5652911249293386, 'f1': 0.6693440428380188}, 'partial': {'correct': 776, 'incorrect': 0, 'partial': 224, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.7284659557013946, 'recall': 0.5019785189372526, 'f1': 0.5943775100401606}, 'strict': {'correct': 776, 'incorrect': 224, 'partial': 0, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.6365873666940115, 'recall': 0.43866591294516677, 'f1': 0.5194109772423026}, 'exact': {'correct': 776, 'incorrect': 224, 'partial': 0, 'missed': 769, 'spurious': 219, 'possible': 1769, 'actual': 1219, 'precision': 0.6365873666940115, 'recall': 0.43866591294516677, 'f1': 0.5194109772423026}}}\n",
      "f1-score: 0.5943775100401606\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(model, benchmark=benchmark, dataset_wise_config=dataset_wise_config, output_dir=None)\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.83      0.88      0.83         6\n",
      "weighted avg       0.89      0.83      0.84         6\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(classification_report([0,0,0,1,1,0], [0,0,0,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_ner_leaderboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
